#!/bin/bash

# set root repo relatively to a test dir
ROOT_REPO=${ROOT_REPO:-$(realpath ../../..)}
test_name=$(basename "$(pwd)")
source "${ROOT_REPO}/e2e-tests/vars.sh"

if oc get projects 2>/dev/null; then
	OPENSHIFT=4
fi

init_temp_dir() {
	rm -rf "$TEMP_DIR"
	mkdir -p "$TEMP_DIR"
}

create_namespace() {
	local namespace=$1

	if [[ -n $OPENSHIFT ]]; then
		set -o pipefail
		if [[ $OPERATOR_NS ]] && (oc get project "$OPERATOR_NS" -o json >/dev/null 2>&1 | jq -r '.metadata.name' >/dev/null 2>&1); then
			oc delete --grace-period=0 --force=true project "$namespace" && sleep 120 || :
		else
			oc delete project "$namespace" && sleep 40 || :
		fi
		wait_for_delete "project/$namespace" || :

		oc new-project "$namespace"
		oc project "$namespace"
		oc adm policy add-scc-to-user hostaccess -z default || :
	else
		kubectl delete namespace $namespace --ignore-not-found || :
		kubectl wait --for=delete namespace "$namespace" || :
		kubectl create namespace $namespace
	fi
}

wait_for_delete() {
	local res="$1"

	echo -n "waiting for $res to be deleted"
	set +o xtrace
	retry=0
	until (kubectl get $res || :) 2>&1 | grep NotFound; do
		sleep 1
		echo -n .
		let retry+=1
		if [ $retry -ge 120 ]; then
			kubectl_bin logs ${OPERATOR_NS:+-n $OPERATOR_NS} $(get_operator_pod)
			echo max retry count $retry reached. something went wrong with operator or kubernetes cluster
			exit 1
		fi
	done
}

deploy_operator() {
	destroy_operator

	if [[ $OPERATOR_NS ]]; then
		create_namespace "${OPERATOR_NS}"
	fi

	kubectl -n "${OPERATOR_NS:-$NAMESPACE}" apply --server-side --force-conflicts -f "${DEPLOY_DIR}/crd.yaml"

	if [ -n "$OPERATOR_NS" ]; then
		kubectl -n "${OPERATOR_NS:-$NAMESPACE}" apply -f "${DEPLOY_DIR}/cw-rbac.yaml"

		yq eval \
			"$(printf 'select(documentIndex==1).spec.template.spec.containers[0].image="%s"' "${IMAGE}")" \
			"${DEPLOY_DIR}/cw-operator.yaml" \
			| yq eval '(select(documentIndex==1).spec.template.spec.containers[] | select(.name=="manager").env[] | select(.name=="DISABLE_TELEMETRY").value) = "true"' \
			| yq eval '(select(documentIndex==1).spec.template.spec.containers[] | select(.name=="manager").env[] | select(.name=="LOG_LEVEL").value) = "DEBUG"' \
			| kubectl -n "${OPERATOR_NS:-$NAMESPACE}" apply -f -
	else
		kubectl -n "${OPERATOR_NS:-$NAMESPACE}" apply -f "${DEPLOY_DIR}/rbac.yaml"

		yq eval \
			"$(printf 'select(documentIndex==1).spec.template.spec.containers[0].image="%s"' "${IMAGE}")" \
			"${DEPLOY_DIR}/operator.yaml" \
			| yq eval '(select(documentIndex==1).spec.template.spec.containers[] | select(.name=="manager").env[] | select(.name=="DISABLE_TELEMETRY").value) = "true"' \
			| yq eval '(select(documentIndex==1).spec.template.spec.containers[] | select(.name=="manager").env[] | select(.name=="LOG_LEVEL").value) = "DEBUG"' \
			| kubectl -n "${OPERATOR_NS:-$NAMESPACE}" apply -f -
	fi
}

destroy_operator() {
	kubectl -n "${OPERATOR_NS:-$NAMESPACE}" delete deployment percona-server-mysql-operator --force --grace-period=0 || true
	if [[ $OPERATOR_NS ]]; then
		kubectl delete namespace $OPERATOR_NS --force --grace-period=0 || true
	fi
}

deploy_non_tls_cluster_secrets() {
	kubectl -n "${NAMESPACE}" apply -f "${TESTS_CONFIG_DIR}/secrets.yaml"
}

deploy_tls_cluster_secrets() {
	kubectl -n "${NAMESPACE}" apply -f "${TESTS_CONFIG_DIR}/ssl-secret.yaml"
}

deploy_client() {
	yq eval "$(printf '.spec.containers[0].image="%s"' "${IMAGE_MYSQL}")" "${TESTS_CONFIG_DIR}/client.yaml" \
		| kubectl -n "${NAMESPACE}" apply -f -
}

apply_minio_secret() {
	kubectl -n "${NAMESPACE}" apply -f "${TESTS_CONFIG_DIR}/minio-secret.yml"
}

apply_s3_storage_secrets() {
	apply_minio_secret
	kubectl -n "${NAMESPACE}" apply -f "${TESTS_CONFIG_DIR}/cloud-secret.yml"
}

deploy_pmm_server() {
	helm uninstall -n "${NAMESPACE}" monitoring || :
	helm repo remove percona || :
	kubectl delete clusterrole monitoring --ignore-not-found
	kubectl delete clusterrolebinding monitoring --ignore-not-found
	helm repo add percona https://percona.github.io/percona-helm-charts/
	helm repo update

	if [[ -n $OPENSHIFT ]]; then
		platform=openshift
		oc create sa pmm-server -n "${NAMESPACE}" || :
		oc adm policy add-scc-to-user privileged -z pmm-server -n "${NAMESPACE}" || :

		if [[ $OPERATOR_NS ]]; then
			timeout 30 oc delete clusterrolebinding $(kubectl get clusterrolebinding | grep 'pmm-ps-operator-' | awk '{print $1}') || :
			oc create clusterrolebinding pmm-ps-operator-cluster-wide --clusterrole=percona-server-mysql-operator --serviceaccount=$NAMESPACE:pmm-server -n "$NAMESPACE"
			oc patch clusterrole/percona-server-mysql-operator --type json -p='[{"op":"add","path": "/rules/-","value":{"apiGroups":["security.openshift.io"],"resources":["securitycontextconstraints"],"verbs":["use"],"resourceNames":["privileged"]}}]' ${OPERATOR_NS:+-n $OPERATOR_NS} || :
		else
			oc create rolebinding pmm-ps-operator-namespace-only --role percona-server-mysql-operator --serviceaccount=$NAMESPACE:pmm-server -n "$NAMESPACE"
			oc patch role/percona-server-mysql-operator --type json -p='[{"op":"add","path": "/rules/-","value":{"apiGroups":["security.openshift.io"],"resources":["securitycontextconstraints"],"verbs":["use"],"resourceNames":["privileged"]}}]' -n "$NAMESPACE" || :
		fi
		local additional_params="--set platform=openshift --set supresshttp2=false --set serviceAccount.create=false --set serviceAccount.name=pmm-server"
	fi

	retry 10 120 helm install monitoring percona/pmm -n "${NAMESPACE}" \
		--set fullnameOverride=monitoring \
		--version ${PMM_SERVER_VERSION} \
		--set image.tag=${IMAGE_PMM_SERVER#*:} \
		--set image.repository=${IMAGE_PMM_SERVER%:*} \
		--set service.type=LoadBalancer \
		$additional_params \
		--force
}

get_pmm_server_token() {
	local key_name=$1

	if [[ -z $key_name ]]; then
		key_name="operator"
	fi

	local ADMIN_PASSWORD
	ADMIN_PASSWORD=$(kubectl -n "${NAMESPACE}" get secret pmm-secret -o jsonpath="{.data.PMM_ADMIN_PASSWORD}" | base64 --decode)

	if [[ -z $ADMIN_PASSWORD ]]; then
		echo "Error: ADMIN_PASSWORD is empty or not found!" >&2
		return 1
	fi

	local create_response create_status_code create_json_response
	create_response=$(curl --insecure -s -X POST -H 'Content-Type: application/json' -H 'Accept: application/json' \
		-d "{\"name\":\"${key_name}\", \"role\":\"Admin\", \"isDisabled\":false}" \
		--user "admin:${ADMIN_PASSWORD}" \
		"https://$(get_service_ip monitoring-service)/graph/api/serviceaccounts" \
		-w "\n%{http_code}")

	create_status_code=$(echo "$create_response" | tail -n1)
	create_json_response=$(echo "$create_response" | sed '$ d')

	if [[ $create_status_code -ne 201 ]]; then
		echo "Error: Failed to create PMM service account. HTTP Status: $create_status_code" >&2
		echo "Response: $create_json_response" >&2
		return 1
	fi

	local service_account_id
	service_account_id=$(echo "$create_json_response" | jq -r '.id')

	if [[ -z $service_account_id || $service_account_id == "null" ]]; then
		echo "Error: Failed to extract service account ID!" >&2
		return 1
	fi

	local token_response token_status_code token_json_response
	token_response=$(curl --insecure -s -X POST -H 'Content-Type: application/json' \
		-d "{\"name\":\"${key_name}\"}" \
		--user "admin:${ADMIN_PASSWORD}" \
		"https://$(get_service_ip monitoring-service)/graph/api/serviceaccounts/${service_account_id}/tokens" \
		-w "\n%{http_code}")

	token_status_code=$(echo "$token_response" | tail -n1)
	token_json_response=$(echo "$token_response" | sed '$ d')

	if [[ $token_status_code -ne 200 ]]; then
		echo "Error: Failed to create token. HTTP Status: $token_status_code" >&2
		echo "Response: $token_json_response" >&2
		return 1
	fi

	echo "$token_json_response" | jq -r '.key'
}

delete_pmm_server_token() {
	local key_name=$1

	if [[ -z $key_name ]]; then
		key_name="operator"
	fi

	local ADMIN_PASSWORD
	ADMIN_PASSWORD=$(kubectl -n "${NAMESPACE}" get secret pmm-secret -o jsonpath="{.data.PMM_ADMIN_PASSWORD}" | base64 --decode)

	if [[ -z $ADMIN_PASSWORD ]]; then
		echo "Error: ADMIN_PASSWORD is empty or not found!" >&2
		return 1
	fi

	local user_credentials="admin:${ADMIN_PASSWORD}"

	local service_accounts_response service_accounts_status
	service_accounts_response=$(curl --insecure -s -X GET --user "${user_credentials}" \
		"https://$(get_service_ip monitoring-service)/graph/api/serviceaccounts/search" \
		-w "\n%{http_code}")

	service_accounts_status=$(echo "$service_accounts_response" | tail -n1)
	service_accounts_json=$(echo "$service_accounts_response" | sed '$ d')

	if [[ $service_accounts_status -ne 200 ]]; then
		echo "Error: Failed to fetch service accounts. HTTP Status: $service_accounts_status" >&2
		echo "Response: $service_accounts_json" >&2
		return 1
	fi

	local service_account_id
	service_account_id=$(echo "$service_accounts_json" | jq -r ".serviceAccounts[] | select(.name == \"${key_name}\").id")

	if [[ -z $service_account_id || $service_account_id == "null" ]]; then
		echo "Service account '${key_name}' not found."
		return 1
	fi

	local tokens_response tokens_status tokens_json
	tokens_response=$(curl --insecure -s -X GET --user "${user_credentials}" \
		"https://$(get_service_ip monitoring-service)/graph/api/serviceaccounts/${service_account_id}/tokens" \
		-w "\n%{http_code}")

	tokens_status=$(echo "$tokens_response" | tail -n1)
	tokens_json=$(echo "$tokens_response" | sed '$ d')

	if [[ $tokens_status -ne 200 ]]; then
		echo "Error: Failed to fetch tokens. HTTP Status: $tokens_status" >&2
		echo "Response: $tokens_json" >&2
		return 1
	fi

	local token_id
	token_id=$(echo "$tokens_json" | jq -r ".[] | select(.name == \"${key_name}\").id")

	if [[ -z $token_id || $token_id == "null" ]]; then
		echo "Token for service account '${key_name}' not found."
		return 1
	fi

	local delete_response delete_status
	delete_response=$(curl --insecure -s -X DELETE --user "${user_credentials}" \
		"https://$(get_service_ip monitoring-service)/graph/api/serviceaccounts/${service_account_id}/tokens/${token_id}" \
		-w "\n%{http_code}")

	delete_status=$(echo "$delete_response" | tail -n1)

	if [[ $delete_status -ne 200 ]]; then
		echo "Error: Failed to delete token. HTTP Status: $delete_status" >&2
		echo "Response: $delete_response" >&2
		return 1
	fi
}

deploy_minio() {
	local access_key
	local secret_key
	access_key="$(kubectl -n "${NAMESPACE}" get secret minio-secret -o jsonpath='{.data.AWS_ACCESS_KEY_ID}' | base64 -d)"
	secret_key="$(kubectl -n "${NAMESPACE}" get secret minio-secret -o jsonpath='{.data.AWS_SECRET_ACCESS_KEY}' | base64 -d)"

	helm uninstall -n "${NAMESPACE}" minio-service || :
	helm repo remove minio || :
	helm repo add minio https://charts.min.io/
	retry 10 60 helm install minio-service \
		-n "${NAMESPACE}" \
		--version "${MINIO_VER}" \
		--set replicas=1 \
		--set mode=standalone \
		--set resources.requests.memory=256Mi \
		--set rootUser=rootuser \
		--set rootPassword=rootpass123 \
		--set "users[0].accessKey"="$(printf '%q' "$(printf '%q' "$access_key")")" \
		--set "users[0].secretKey"="$(printf '%q' "$(printf '%q' "$secret_key")")" \
		--set "users[0].policy"=consoleAdmin \
		--set service.type=ClusterIP \
		--set configPathmc=/tmp/.minio/ \
		--set persistence.size=2G \
		--set securityContext.enabled=false \
		minio/minio
	MINIO_POD=$(kubectl -n "${NAMESPACE}" get pods --selector=release=minio-service -o 'jsonpath={.items[].metadata.name}')
	wait_pod $MINIO_POD

	# create bucket
	kubectl -n "${NAMESPACE}" run -i --rm aws-cli --image=perconalab/awscli --restart=Never -- \
		bash -c "AWS_ACCESS_KEY_ID='$access_key' AWS_SECRET_ACCESS_KEY='$secret_key' AWS_DEFAULT_REGION=us-east-1 \
        /usr/bin/aws --endpoint-url http://minio-service:9000 s3 mb s3://operator-testing"
}

prepare_vault_tls() {
	local name=$1
	local namespace=$2
	local csr_name=vault-csr-${RANDOM}
	local csr_api_ver="v1"
	local csr_signer

	if [[ ${platform} == "eks" ]]; then
		csr_signer="  signerName: beta.eks.amazonaws.com/app-serving"
	else
		csr_signer="  signerName: kubernetes.io/kubelet-serving"
	fi

	openssl genrsa -out ${tmp_dir}/vault.key 2048
	cat <<EOF >${tmp_dir}/csr.conf
[req]
req_extensions = v3_req
distinguished_name = req_distinguished_name
[req_distinguished_name]
[ v3_req ]
basicConstraints = CA:FALSE
keyUsage = nonRepudiation, digitalSignature, keyEncipherment
extendedKeyUsage = serverAuth
subjectAltName = @alt_names
[alt_names]
DNS.1 = ${name}
DNS.2 = ${name}.${namespace}
DNS.3 = ${name}.${namespace}.svc
DNS.4 = ${name}.${namespace}.svc.cluster.local
IP.1 = 127.0.0.1
EOF

	openssl req -new \
		-key ${tmp_dir}/vault.key \
		-subj "/CN=system:node:${name}.${namespace}.svc;/O=system:nodes" \
		-out ${tmp_dir}/server.csr \
		-config ${tmp_dir}/csr.conf

	cat <<EOF >${tmp_dir}/csr.yaml
apiVersion: certificates.k8s.io/${csr_api_ver}
kind: CertificateSigningRequest
metadata:
  name: ${csr_name}
spec:
  groups:
  - system:authenticated
  request: $(cat ${tmp_dir}/server.csr | base64 | tr -d '\n')
${csr_signer}
  usages:
  - digital signature
  - key encipherment
  - server auth
EOF

	kubectl create -n ${namespace} -f ${tmp_dir}/csr.yaml
	sleep 10
	kubectl certificate approve ${csr_name}
	kubectl get csr ${csr_name} -o jsonpath='{.status.certificate}' >${tmp_dir}/serverCert
	openssl base64 -in ${tmp_dir}/serverCert -d -A -out ${tmp_dir}/vault.crt
	kubectl config view --raw --minify --flatten -o jsonpath='{.clusters[].cluster.certificate-authority-data}' | base64 -d >${tmp_dir}/vault.ca
	if [[ ${platform} == "openshift" ]]; then
		if [[ "x$(kubectl get namespaces | awk '{print $1}' | grep openshift-kube-controller-manager-operator)" != "x" ]]; then
			#Detecting openshift 4+
			kubectl -n openshift-kube-controller-manager-operator get secret csr-signer -o jsonpath='{.data.tls\.crt}' \
				| base64 -d >${tmp_dir}/vault.ca
		else
			ca_secret_name=$(kubectl -n default get secrets \
				| grep default \
				| grep service-account-token \
				| head -n 1 \
				| awk {'print $1'})
			kubectl -n default get secret ${ca_secret_name} -o jsonpath='{.data.ca\.crt}' \
				| base64 -d >${tmp_dir}/vault.ca
		fi
	fi

	kubectl create secret generic ${name} \
		--namespace ${namespace} \
		--from-file=vault.key=${tmp_dir}/vault.key \
		--from-file=vault.crt=${tmp_dir}/vault.crt \
		--from-file=vault.ca=${tmp_dir}/vault.ca

}

_deploy_vault() {
	local name=$1
	local protocol=$2
	local platform=$3
	local namespace=$4
	local tmp_dir=$5

	if kubectl get ns | grep ${namespace}; then
		echo "${namespace} is already exist, assuming Vault is running there."
		return
	fi

	rm -rf ${tmp_dir}
	mkdir -p ${tmp_dir}

	helm repo add hashicorp https://helm.releases.hashicorp.com
	helm repo update

	kubectl create namespace "${namespace}"
	helm uninstall "$name" || :

	echo "install Vault $name"

	if [[ ${platform} == "openshift" ]]; then
		oc patch clusterrole system:auth-delegator --type='json' -p '[{"op":"add","path":"/rules/-", "value":{"apiGroups":["security.openshift.io"], "attributeRestrictions":null, "resourceNames": ["privileged"], "resources":["securitycontextconstraints"],"verbs":["use"]}}]'
	fi

	if [ $protocol == "https" ]; then
		prepare_vault_tls ${name} ${namespace}
		helm install $name hashicorp/vault \
			--disable-openapi-validation \
			--version ${VAULT_VER} \
			--namespace "${namespace}" \
			--set dataStorage.enabled=false \
			--set global.tlsDisable=false \
			--set global.logLevel="trace" \
			--set global.platform="${platform}" \
			--set server.extraVolumes[0].type=secret \
			--set server.extraVolumes[0].name=$name \
			--set server.extraEnvironmentVars.VAULT_CACERT=/vault/userconfig/$name/vault.ca \
			--set server.standalone.config="
listener \"tcp\" {
    address = \"[::]:8200\"
    cluster_address = \"[::]:8201\"
    tls_cert_file = \"/vault/userconfig/$name/vault.crt\"
    tls_key_file  = \"/vault/userconfig/$name/vault.key\"
    tls_client_ca_file = \"/vault/userconfig/$name/vault.ca\"
}

storage \"file\" {
    path = \"/vault/data\"
}"
	else
		helm install $name hashicorp/vault \
			--disable-openapi-validation \
			--version ${VAULT_VER} \
			--namespace "${namespace}" \
			--set dataStorage.enabled=false \
			--set global.logLevel="trace" \
			--set global.platform="${platform}"
	fi

	if [[ ${platform} == "openshift" ]]; then
		oc patch clusterrole $name-agent-injector-clusterrole --type='json' -p '[{"op":"add","path":"/rules/-", "value":{"apiGroups":["security.openshift.io"], "attributeRestrictions":null, "resourceNames": ["privileged"], "resources":["securitycontextconstraints"],"verbs":["use"]}}]'
		oc adm policy add-scc-to-user privileged $name-agent-injector
	fi

	set +o xtrace
	retry=0
	echo -n "waiting for pod/$name-0 to be ready"
	until kubectl get -n ${namespace} pod/$name-0 -o 'jsonpath={.status.containerStatuses[0].state}' 2>/dev/null | grep 'running'; do
		echo -n .
		sleep 1
		let retry+=1
		if [[ $retry -ge 480 ]]; then
			kubectl -n ${namespace} describe pod/$name-0
			kubectl -n ${namespace} logs $name-0
			echo max retry count "$retry" reached. something went wrong with vault
			exit 1
		fi
	done
	set -o xtrace

	kubectl -n ${namespace} exec -it $name-0 -- vault operator init -tls-skip-verify -key-shares=1 -key-threshold=1 -format=json >"$tmp_dir/$name"
	local unsealKey=$(jq -r ".unseal_keys_b64[]" <"$tmp_dir/$name")
	local token=$(jq -r ".root_token" <"$tmp_dir/$name")
	sleep 10

	kubectl -n ${namespace} exec -it $name-0 -- vault operator unseal -tls-skip-verify "$unsealKey"
	kubectl -n ${namespace} exec -it $name-0 -- \
		sh -c "export VAULT_TOKEN=$token && export VAULT_LOG_LEVEL=trace \
                && vault secrets enable --version=1 -tls-skip-verify -path=secret kv \
                && vault audit enable file file_path=/vault/vault-audit.log"
	sleep 10
}

deploy_vault() {
	local name=${1:-vault-service}
	local protocol=${2:-http}
	local platform=${3:-kubernetes}
	local namespace=${4:-${name}}

	local tmp_dir=/tmp/vault
	echo "Using tmp dir: ${tmp_dir}"

	_deploy_vault ${name} ${protocol} ${platform} ${namespace} ${tmp_dir}

	local unsealKey=$(jq -r ".unseal_keys_b64[]" <"$tmp_dir/$name")
	local token=$(jq -r ".root_token" <"$tmp_dir/$name")

	cat ${ROOT_REPO}/e2e-tests/conf/vault-secret.yaml \
		| sed -e "s/#token/$token/" \
		| sed -e "s/#vault_url/$protocol:\/\/$name.$name.svc.cluster.local:8200/" \
		| sed -e "s/#secret/secret/" >"${tmp_dir}/vault-secret.yaml"

	if [ $protocol == "https" ]; then
		sed -e 's/^/    /' ${tmp_dir}/vault.ca >${tmp_dir}/vault.new.ca
		sed -i "s/#vault_ca/vault_ca/" "${tmp_dir}/vault-secret.yaml"
		sed -i "/#certVal/r ${tmp_dir}/vault.new.ca" "${tmp_dir}/vault-secret.yaml"
		sed -i "/#certVal/d" "${tmp_dir}/vault-secret.yaml"
	else
		sed -i "/#vault_ca/d" "${tmp_dir}/vault-secret.yaml"
	fi

	kubectl apply -n "${NAMESPACE}" -f ${tmp_dir}/vault-secret.yaml
}

retry() {
	local max=$1
	local delay=$2
	shift 2 # cut delay and max args
	local n=1

	until "$@"; do
		if [[ $n -ge $max ]]; then
			echo "The command ${*} has failed after $n attempts."
			exit 1
		fi
		((n++))
		sleep $delay
	done
}

get_operator_pod() {
	kubectl get pods -n "${OPERATOR_NS:-$NAMESPACE}" \
		--selector=app.kubernetes.io/name=percona-server-mysql-operator \
		-o 'jsonpath={.items[].metadata.name}'
}

get_cr() {
	local name_suffix=$1

	yq eval "$(printf '.metadata.name="%s"' "${test_name}${name_suffix:+-$name_suffix}")" "${DEPLOY_DIR}/cr.yaml" \
		| yq eval "$(printf '.spec.initContainer.image="%s"' "${IMAGE}")" - \
		| yq eval '.spec.secretsName="test-secrets"' - \
		| yq eval '.spec.sslSecretName="test-ssl"' - \
		| yq eval '.spec.upgradeOptions.apply="disabled"' - \
		| yq eval '.spec.mysql.clusterType="async"' - \
		| yq eval '.spec.mysql.gracePeriod=30' - \
		| yq eval '.spec.orchestrator.enabled=true' - \
		| yq eval "$(printf '.spec.mysql.image="%s"' "${IMAGE_MYSQL}")" - \
		| yq eval "$(printf '.spec.backup.image="%s"' "${IMAGE_BACKUP}")" - \
		| yq eval "$(printf '.spec.orchestrator.image="%s"' "${IMAGE_ORCHESTRATOR}")" - \
		| yq eval "$(printf '.spec.proxy.router.image="%s"' "${IMAGE_ROUTER}")" - \
		| yq eval "$(printf '.spec.toolkit.image="%s"' "${IMAGE_TOOLKIT}")" - \
		| yq eval "$(printf '.spec.proxy.haproxy.image="%s"' "${IMAGE_HAPROXY}")" - \
		| yq eval "$(printf '.spec.pmm.image="%s"' "${IMAGE_PMM_CLIENT}")" - \
		| if [ -n "${MINIKUBE}" ]; then
			yq eval '(.. | select(has("antiAffinityTopologyKey")).antiAffinityTopologyKey) |= "none"' - \
				| yq eval '.spec.proxy.haproxy.resources.requests.cpu="300m"' -
		else
			yq eval -
		fi
}

get_client_pod() {
	kubectl -n "${NAMESPACE}" get pods \
		--selector=name=mysql-client \
		-o 'jsonpath={.items[].metadata.name}'
}

run_mysql() {
	local command="$1"
	local uri="$2"
	local pod="$3"

	client_pod=$(get_client_pod)
	wait_pod $client_pod 1>&2

	kubectl -n "${NAMESPACE}" exec "${pod:-mysql-client}" -- \
		bash -c "printf '%s\n' \"${command}\" | mysql -sN $uri" 2>&1 \
		| sed -e 's/mysql: //' \
		| (grep -v 'Using a password on the command line interface can be insecure.' || :)
}

run_mysqlsh() {
	local command="$1"
	local uri="$2"
	local pod="$3"

	client_pod=$(get_client_pod)
	wait_pod $client_pod 1>&2

	kubectl -n "${NAMESPACE}" exec "${pod:-mysql-client}" -- \
		bash -c "printf '%s\n' \"${command}\" | mysqlsh --sql --quiet-start=2 $uri" 2>/dev/null \
		| tail -n +2
}

get_innodb_cluster_status() {
	local uri="$1"

	client_pod=$(get_client_pod)
	wait_pod $client_pod 1>&2

	kubectl -n "${NAMESPACE}" exec "${client_pod}" -- mysqlsh --js --quiet-start=2 --uri ${uri} -- cluster status
}

wait_until_innodb_ok() {
	local uri="$1"

	local retry=0
	until [[ $(get_innodb_cluster_status ${uri} | jq -r .defaultReplicaSet.status) == "OK" ]]; do
		sleep 5
		retry=$((retry + 1))
	done
}

run_curl() {
	kubectl -n "${NAMESPACE}" exec mysql-client -- bash -c "curl -s -k $*"
}

get_innodb_cluster_name() {
	echo $(get_cluster_name) | tr -cd '[^a-zA-Z0-9_]+'
}

get_mysqlsh_uri_for_pod() {
	local pod=$1

	echo "root:root_password@${pod}.$(get_cluster_name)-mysql.${NAMESPACE}"
}

get_mysqlsh_uri() {
	local idx=${1:-0}

	echo "root:root_password@$(get_cluster_name)-mysql-${idx}.$(get_cluster_name)-mysql.${NAMESPACE}"
}

get_gr_status() {
	local uri="$1"
	local pod="$2"

	client_pod=$(get_client_pod)

	kubectl -n "${NAMESPACE}" exec "${pod:-mysql-client}" -- mysqlsh --js --uri $uri --cluster --result-format json -- cluster status \
		| sed -e 's/mysql: //' \
		| (grep -v 'Using a password on the command line interface can be insecure.' || :)
}

get_cluster_name() {
	kubectl -n "${NAMESPACE}" get ps -o jsonpath='{.items[0].metadata.name}'
}

get_mysql_service() {
	local cluster=$1

	echo "${cluster}-mysql"
}

get_router_service() {
	local cluster=$1

	echo "${cluster}-router"
}

get_haproxy_svc() {
	local cluster=$1

	echo "${cluster}-haproxy"
}

get_orc_svc() {
	local cluster=$1

	echo "${cluster}-orc"
}

get_mysql_headless_fqdn() {
	local cluster=$1
	local index=$2

	echo "${cluster}-mysql-${index}.${cluster}-mysql"
}

get_orc_headless_fqdn() {
	local cluster=$1
	local index=$2

	echo "${cluster}-orc-${index}.${cluster}-orc"
}

get_metric_values() {
	local metric=$1
	local instance=$2
	local token=$3
	local start=$($date -u "+%s" -d "-1 minute")
	local end=$($date -u "+%s")

	set +o xtrace
	retry=0
	until run_curl "-H 'Authorization: Bearer ${token}'" "https://monitoring-service/graph/api/datasources/proxy/1/api/v1/query_range?query=min%28$metric%7Bnode_name%3D%7E%22$instance%22%7d%20or%20$metric%7Bnode_name%3D%7E%22$instance%22%7D%29&start=$start&end=$end&step=60" | jq '.data.result[0].values[][1]' | grep '^"[0-9]*"$'; do
		sleep 1
		let retry+=1
		if [ $retry -ge 30 ]; then
			echo "Max retry count $retry reached. Data about instance $instance was not collected!"
			exit 1
		fi
	done
	set -o xtrace
}

get_qan20_values() {
	local instance=$1
	local token=$2
	local start=$($date -u "+%Y-%m-%dT%H:%M:%S" -d "-30 minute")
	local end=$($date -u "+%Y-%m-%dT%H:%M:%S")
	local endpoint=monitoring-service

	local payload=$(
		cat <<EOF
{
   "columns":[
      "load",
      "num_queries",
      "query_time"
   ],
   "first_seen": false,
   "group_by": "queryid",
   "include_only_fields": [],
   "keyword": "",
   "labels": [
       {
           "key": "cluster",
           "value": ["monitoring"]
   }],
   "limit": 10,
   "offset": 0,
   "order_by": "-load",
   "main_metric": "load",
   "period_start_from": "$($date -u -d '-12 hour' '+%Y-%m-%dT%H:%M:%S%:z')",
   "period_start_to": "$($date -u '+%Y-%m-%dT%H:%M:%S%:z')"
}
EOF
	)

	run_curl -XPOST -d "'$(echo ${payload} | sed 's/\n//g')'" "-H 'Authorization: Bearer ${token}'" "https://${user_pass}@${endpoint}/v1/qan/metrics:getReport" \
		| jq '.rows[].fingerprint'
}

get_mysql_pods() {
	kubectl get pod -n "${NAMESPACE}" --no-headers --selector=app.kubernetes.io/name=mysql | awk '{print $1}'
}

get_router_pods() {
	kubectl get pod -n "${NAMESPACE}" --no-headers --selector=app.kubernetes.io/name=router | awk '{print $1}'
}

get_mysql_users() {
	local args=$1

	run_mysql "SELECT user FROM mysql.user" "${args}" | grep -vE "mysql|root|percona.telemetry"
}

get_service_ip() {
	local service=$1

	while (kubectl get service/$service -n "${NAMESPACE}" -o 'jsonpath={.spec.type}' 2>&1 || :) | grep -q NotFound; do
		sleep 1
	done
	if [ "$(kubectl get service/$service -n "${NAMESPACE}" -o 'jsonpath={.spec.type}')" = "ClusterIP" ]; then
		kubectl get service/$service -n "${NAMESPACE}" -o 'jsonpath={.spec.clusterIP}'
		return
	fi
	until kubectl get service/$service -n "${NAMESPACE}" -o 'jsonpath={.status.loadBalancer.ingress[]}' 2>&1 | egrep -q "hostname|ip"; do
		sleep 1
	done
	kubectl get service/$service -n "${NAMESPACE}" -o 'jsonpath={.status.loadBalancer.ingress[].ip}'
	kubectl get service/$service -n "${NAMESPACE}" -o 'jsonpath={.status.loadBalancer.ingress[].hostname}'
}

wait_cluster_consistency_async() {
	local cluster_name=${1}
	local cluster_size=${2}
	local orc_size=${3}

	if [ -z "${orc_size}" ]; then
		orc_size=3
	fi

	sleep 7 # wait for two reconcile loops ;)  3 sec x 2 times + 1 sec = 7 seconds
	until [[ "$(kubectl get ps "${cluster_name}" -n "${NAMESPACE}" -o jsonpath='{.status.mysql.state}')" == "ready" &&
	"$(kubectl get ps "${cluster_name}" -n "${NAMESPACE}" -o jsonpath='{.status.mysql.ready}')" == "${cluster_size}" &&
	"$(kubectl get ps "${cluster_name}" -n "${NAMESPACE}" -o jsonpath='{.status.orchestrator.ready}')" == "${orc_size}" &&
	"$(kubectl get ps "${cluster_name}" -n "${NAMESPACE}" -o jsonpath='{.status.orchestrator.state}')" == "ready" &&
	"$(kubectl get ps "${cluster_name}" -n "${NAMESPACE}" -o jsonpath='{.status.state}')" == "ready" ]]; do
		echo 'waiting for cluster readyness (async)'
		sleep 15
	done
}

wait_cluster_consistency_gr() {
	local cluster_name=${1}
	local cluster_size=${2}
	local router_size=${3}

	if [ -z "${router_size}" ]; then
		router_size=3
	fi

	sleep 7 # wait for two reconcile loops ;)  3 sec x 2 times + 1 sec = 7 seconds
	until [[ "$(kubectl get ps "${cluster_name}" -n "${NAMESPACE}" -o jsonpath='{.status.mysql.state}')" == "ready" &&
	"$(kubectl get ps "${cluster_name}" -n "${NAMESPACE}" -o jsonpath='{.status.mysql.ready}')" == "${cluster_size}" &&
	"$(kubectl get ps "${cluster_name}" -n "${NAMESPACE}" -o jsonpath='{.status.router.ready}')" == "${router_size}" &&
	"$(kubectl get ps "${cluster_name}" -n "${NAMESPACE}" -o jsonpath='{.status.router.state}')" == "ready" &&
	"$(kubectl get ps "${cluster_name}" -n "${NAMESPACE}" -o jsonpath='{.status.state}')" == "ready" ]]; do
		echo 'waiting for cluster readyness (group replication)'
		sleep 15
	done
}

wait_pod() {
	local pod=$1

	set +o xtrace
	retry=0
	echo -n $pod
	until kubectl get pod/$pod -n "${NAMESPACE}" -o jsonpath='{.status.containerStatuses[0].ready}' 2>/dev/null | grep 'true'; do
		sleep 1
		echo -n .
		let retry+=1
		if [ $retry -ge 360 ]; then
			kubectl describe pod/$pod -n "${NAMESPACE}"
			kubectl logs $pod -n "${NAMESPACE}"
			kubectl logs $(get_operator_pod) -n "${OPERATOR_NS:-$NAMESPACE}" \
				| grep -v 'level=info' \
				| grep -v 'level=debug' \
				| grep -v 'Getting tasks for pod' \
				| grep -v 'Getting pods from source' \
				| tail -100
			echo max retry count $retry reached. something went wrong with operator or kubernetes cluster
			exit 1
		fi
	done
	set -o xtrace
}

wait_deployment() {
	local name=$1
	local target_namespace=${2:-"$namespace"}

	sleep 10
	set +o xtrace
	retry=0
	echo -n $name
	until [ -n "$(kubectl -n ${target_namespace} get deployment $name -o jsonpath='{.status.replicas}')" \
		-a "$(kubectl -n ${target_namespace} get deployment $name -o jsonpath='{.status.replicas}')" \
		== "$(kubectl -n ${target_namespace} get deployment $name -o jsonpath='{.status.readyReplicas}')" ]; do
		sleep 1
		echo -n .
		let retry+=1
		if [ $retry -ge 360 ]; then
			kubectl logs $(get_operator_pod) -c operator \
				| grep -v 'level=info' \
				| grep -v 'level=debug' \
				| tail -100
			echo max retry count $retry reached. something went wrong with operator or kubernetes cluster
			exit 1
		fi
	done
	echo
	set -o xtrace
}

check_auto_tuning() {
	local RAM_SIZE=$1
	local RDS_MEM_INSTANCE=12582880
	local CUSTOM_INNODB_SIZE=$2
	local CUSTOM_CONNECTIONS=$3

	local INNODB_SIZE=$(run_mysql \
		'SELECT @@innodb_buffer_pool_size;' \
		"-h $(get_haproxy_svc "$(get_cluster_name)") -uroot -proot_password")
	local CONNECTIONS=$(run_mysql \
		'SELECT @@max_connections;' \
		"-h $(get_haproxy_svc "$(get_cluster_name)") -uroot -proot_password")

	if [[ -n ${CUSTOM_INNODB_SIZE} ]]; then
		if [[ ${INNODB_SIZE} != ${CUSTOM_INNODB_SIZE} ]]; then
			echo "innodb_buffer_pool_size is set to ${INNODB_SIZE}, which does not correlate with ${CUSTOM_INNODB_SIZE} from custom config"
			exit 1
		fi
	else
		if [[ ${INNODB_SIZE} != $((RAM_SIZE * 50 / 100)) ]]; then
			echo "innodb_buffer_pool_size is set to ${INNODB_SIZE}, which does not correlate with cr.pxc.limits.memory * 0.5"
			exit 1
		fi
	fi

	if [[ -n ${CUSTOM_CONNECTIONS} ]]; then
		if [[ ${CONNECTIONS} != ${CUSTOM_CONNECTIONS} ]]; then
			echo "max_connections is set to ${AUTO_CONNECTIONS}, which does not correlate with ${CUSTOM_CONNECTIONS} from custom config"
			exit 1
		fi
	else
		if [[ ${CONNECTIONS} != $((RAM_SIZE / RDS_MEM_INSTANCE)) ]]; then
			echo "max_connections is set to ${CONNECTIONS}, which does not correlate with cr.pxc.limits.memory / ${RDS_MEM_INSTANCE}"
			exit 1
		fi
	fi
}

get_mysql_router_service() {
	local cluster=$1

	echo "${cluster}-router"
}

deploy_version_service() {
	kubectl create configmap -n "${OPERATOR_NS:-$NAMESPACE}" versions \
		--from-file "${TESTS_CONFIG_DIR}/operator.9.9.9.ps-operator.dep.json" \
		--from-file "${TESTS_CONFIG_DIR}/operator.9.9.9.ps-operator.json"

	kubectl apply -n "${OPERATOR_NS:-$NAMESPACE}" -f "${TESTS_CONFIG_DIR}/vs.yaml"

	sleep 5
}

deploy_cert_manager() {
	kubectl create namespace cert-manager || :
	kubectl label namespace cert-manager certmanager.k8s.io/disable-validation=true || :
	kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v${CERT_MANAGER_VER}/cert-manager.yaml --validate=false || : 2>/dev/null
}

destroy_cert_manager() {
	kubectl delete -f https://github.com/cert-manager/cert-manager/releases/download/v${CERT_MANAGER_VER}/cert-manager.yaml --validate=false || : 2>/dev/null
	kubectl delete --grace-period=0 --force=true namespace cert-manager
}

get_primary_from_label() {
	kubectl -n "${NAMESPACE}" get pods -l mysql.percona.com/primary=true -ojsonpath="{.items[0].metadata.name}"
}

get_primary_from_haproxy() {
	local haproxy_pod=$1
	local haproxy_pod_ip=$(kubectl -n "${NAMESPACE}" get pods ${haproxy_pod} -o jsonpath="{.status.podIP}")

	run_mysql "SHOW VARIABLES LIKE '%hostname%';" "-h ${haproxy_pod_ip} -P3306 -uroot -proot_password" | awk '{print $2}'
}

get_primary_from_group_replication() {
	run_mysql \
		"SELECT MEMBER_HOST FROM performance_schema.replication_group_members where MEMBER_ROLE='PRIMARY';" \
		"-h $(get_mysql_router_service $(get_cluster_name)) -P 6446 -uroot -proot_password" \
		| cut -d'.' -f1
}

verify_certificate_sans() {
	local certificate=$1
	local expected_sans=$2
	local have=$(mktemp)
	local want=$(mktemp)

	kubectl -n "${NAMESPACE}" get certificate "${certificate}" -o jsonpath='{.spec.dnsNames}' | jq '.' >"${have}"
	echo "${expected_sans}" | jq '.' >"${want}"

	diff "${have}" "${want}"
}

check_passwords_leak() {
	local secrets
	local passwords
	local pods

	secrets=$(kubectl get secrets -o json | jq -r '.items[].data | to_entries | .[] | select(.key | (endswith(".crt") or endswith(".key") or endswith(".pub") or endswith(".pem") or endswith(".p12") or test("namespace")) | not) | .value')
	passwords="$(for i in $secrets; do
		base64 -d <<<$i
		echo
	done) $secrets"
	pods=$(kubectl -n "${NAMESPACE}" get pods -o name | awk -F "/" '{print $2}')

	collect_logs() {
		local containers
		local count

		NS=$1
		for p in $pods; do
			containers=$(kubectl -n "$NS" get pod $p -o jsonpath='{.spec.containers[*].name}')
			for c in $containers; do
				kubectl -n "$NS" logs $p -c $c >${TEMP_DIR}/logs_output-$p-$c.txt
				echo logs saved in: ${TEMP_DIR}/logs_output-$p-$c.txt
				for pass in $passwords; do
					count=$(grep -c --fixed-strings -- "$pass" ${TEMP_DIR}/logs_output-$p-$c.txt || :)
					count=$(echo "$count" | awk '{if ($1 ~ /^[0-9]+$/) print $1; else print 0}')
					if [[ $count != 0 ]]; then
						echo leaked passwords are found in log ${TEMP_DIR}/logs_output-$p-$c.txt
						false
					fi
				done
			done
			echo
		done
	}

	collect_logs $NAMESPACE
	if [ -n "$OPERATOR_NS" ]; then
		pods=$(kubectl -n "${OPERATOR_NS}" get pods -o name | awk -F "/" '{print $2}')
		collect_logs $OPERATOR_NS
	fi
}

deploy_chaos_mesh() {
	destroy_chaos_mesh

	helm repo add chaos-mesh https://charts.chaos-mesh.org
	if [ -n "${MINIKUBE}" ]; then
		helm install chaos-mesh chaos-mesh/chaos-mesh --namespace=${NAMESPACE} --set chaosDaemon.runtime=docker --set dashboard.create=false --version ${CHAOS_MESH_VER}
	else
		helm install chaos-mesh chaos-mesh/chaos-mesh --namespace=${NAMESPACE} --set chaosDaemon.runtime=containerd --set chaosDaemon.socketPath=/run/containerd/containerd.sock --set dashboard.create=false --version ${CHAOS_MESH_VER}
	fi
	if [[ -n $OPENSHIFT ]]; then
		oc adm policy add-scc-to-user privileged -z chaos-daemon --namespace=${NAMESPACE}
	fi

	echo "Waiting for chaos-mesh DaemonSet to be ready..."
	until [ "$(kubectl get daemonset chaos-daemon -n ${NAMESPACE} -o jsonpath='{.status.numberReady}')" = "$(kubectl get daemonset chaos-daemon -n ${NAMESPACE} -o jsonpath='{.status.desiredNumberScheduled}')" ]; do
		echo "Waiting for DaemonSet chaos-daemon..."
		sleep 5
	done
}

destroy_chaos_mesh() {
	local chaos_mesh_ns=$(helm list --all-namespaces --filter chaos-mesh | tail -n1 | awk -F' ' '{print $2}' | sed 's/NAMESPACE//')

	if [ -n "${chaos_mesh_ns}" ]; then
		helm uninstall --wait --timeout 60s chaos-mesh --namespace ${chaos_mesh_ns} || :
	fi
	timeout 30 kubectl delete MutatingWebhookConfiguration $(kubectl get MutatingWebhookConfiguration | grep 'chaos-mesh' | awk '{print $1}') || :
	timeout 30 kubectl delete ValidatingWebhookConfiguration $(kubectl get ValidatingWebhookConfiguration | grep 'chaos-mesh' | awk '{print $1}') || :
	timeout 30 kubectl delete ValidatingWebhookConfiguration $(kubectl get ValidatingWebhookConfiguration | grep 'validate-auth' | awk '{print $1}') || :
	for i in $(kubectl api-resources | grep chaos-mesh | awk '{print $1}'); do
		kubectl get ${i} --all-namespaces --no-headers -o custom-columns=Kind:.kind,Name:.metadata.name,NAMESPACE:.metadata.namespace \
			| while read -r line; do
				local kind=$(echo "$line" | awk '{print $1}')
				local name=$(echo "$line" | awk '{print $2}')
				local namespace=$(echo "$line" | awk '{print $3}')
				kubectl patch $kind $name -n "${namespace}" --type=merge -p '{"metadata":{"finalizers":[]}}' || :
			done
		timeout 30 kubectl delete ${i} --all --all-namespaces || :
	done
	timeout 30 kubectl delete crd $(kubectl get crd | grep 'chaos-mesh.org' | awk '{print $1}') || :
	timeout 30 kubectl delete clusterrolebinding $(kubectl get clusterrolebinding | grep 'chaos-mesh' | awk '{print $1}') || :
	timeout 30 kubectl delete clusterrole $(kubectl get clusterrole | grep 'chaos-mesh' | awk '{print $1}') || :
}

kill_pods() {
	local ns=$1
	local selector=$2
	local pod_label=$3
	local label_value=$4
	local chaos_name=$5

	if [ "${selector}" == "pod" ]; then
		yq eval '
			.metadata.name = "'${chaos_name}'" |
			del(.spec.selector.pods.test-namespace) |
			.spec.selector.pods.'${ns}'[0] = "'${pod_label}'"' ${TESTS_CONFIG_DIR}/chaos-pod-kill.yml \
			| kubectl apply --namespace ${ns} -f -
	elif [ "${selector}" == "label" ]; then
		yq eval '
			.metadata.name = "'${chaos_name}'" |
			.spec.mode = "all" |
			del(.spec.selector.pods) |
			.spec.selector.labelSelectors."'${pod_label}'" = "'${label_value}'"' ${TESTS_CONFIG_DIR}/chaos-pod-kill.yml \
			| kubectl apply --namespace ${ns} -f -
	fi
	sleep 5
}

failure_pod() {
	local ns=$1
	local pod=$2
	local chaos_name=$3

	yq eval '
        .metadata.name = "'${chaos_name}'" |
        del(.spec.selector.pods.test-namespace) |
        .spec.selector.pods.'${ns}'[0] = "'${pod}'"' ${TESTS_CONFIG_DIR}/chaos-pod-failure.yml \
		| kubectl apply --namespace ${ns} -f -
	sleep 5
}

network_loss() {
	local ns=$1
	local pod=$2
	local chaos_name=$3

	yq eval '
        .metadata.name = "'${chaos_name}'" |
        del(.spec.selector.pods.test-namespace) |
        .spec.selector.pods.'${ns}'[0] = "'${pod}'"' ${TESTS_CONFIG_DIR}/chaos-network-loss.yml \
		| kubectl apply --namespace ${ns} -f -
	sleep 5
}

wait_until_chaos_applied() {
	local chaos_type=$1
	local chaos_name=$2

	local resource
	case ${chaos_type} in
		"kill" | "failure" | "full-cluster-crash")
			resource=podchaos/${chaos_name}
			;;
		"network")
			resource=networkchaos/${chaos_name}
			;;
	esac

	local retry=0
	until [[ ${retry} == 30 ]]; do
		sleep 10
		retry=$((retry + 1))

		succeeded=$(kubectl -n ${NAMESPACE} get ${resource} -o yaml \
			| yq '.status.experiment.containerRecords[].events[]
                  | select(.operation == "Apply" and .type == "Succeeded")')

		if [[ -n ${succeeded} ]]; then
			return
		fi
	done

	echo "Timeout (300s) exceeded while waiting for chaos to be applied"
	exit 1
}

wait_until_chaos_recovered() {
	local chaos_type=$1
	local chaos_name=$2

	local resource
	case ${chaos_type} in
		"kill" | "failure")
			resource=podchaos/${chaos_name}
			;;
		"network")
			resource=networkchaos/${chaos_name}
			;;
	esac

	local retry=0
	until [[ ${retry} == 30 ]]; do
		sleep 10
		retry=$((retry + 1))

		succeeded=$(kubectl -n ${NAMESPACE} get ${resource} -o yaml \
			| yq '.status.experiment.containerRecords[].events[]
                  | select(.operation == "Recover" and .type == "Succeeded")')

		if [[ -n ${succeeded} ]]; then
			return
		fi
	done

	echo "Timeout (300s) exceeded while waiting for chaos to be recovered"
	exit 1
}

check_primary_chaos() {
	local chaos_type=$1
	local ns=$2
	local primary_before_failure=$3

	local chaos_name
	case ${chaos_type} in
		"kill")
			chaos_name="chaos-pod-kill-primary"
			kill_pods "${ns}" "pod" "${primary_before_failure}" "" "${chaos_name}"
			;;
		"full-cluster-crash")
			chaos_name="chaos-kill-label-cluster-crash"
			kill_pods "${ns}" "label" "app.kubernetes.io/instance" "gr-self-healing" "${chaos_name}"
			;;
		"failure")
			chaos_name="chaos-pod-failure-primary"
			failure_pod "${ns}" "${primary_before_failure}" "${chaos_name}"
			;;
		"network")
			chaos_name="chaos-pod-network-loss-primary"
			network_loss "${ns}" "${primary_before_failure}" "${chaos_name}"
			;;
	esac

	wait_until_chaos_applied ${chaos_type} ${chaos_name}
	if [[ ${chaos_type} == "failure" || ${chaos_type} == "network" ]]; then
		wait_until_chaos_recovered ${chaos_type} ${chaos_name}
	fi

	wait_cluster_consistency_gr "$(get_cluster_name)" 3 3

	primary_after_failure=$(get_primary_from_group_replication)
	uri=$(get_mysqlsh_uri_for_pod ${primary_after_failure})
	wait_until_innodb_ok ${uri}

	if [[ ${primary_before_failure} == "${primary_after_failure}" ]]; then
		echo "primary pod was not killed! something went wrong."
		exit 1
	fi

	uri=$(get_mysqlsh_uri_for_pod $(get_primary_from_group_replication))
	online_members=$(get_innodb_cluster_status ${uri} \
		| jq .defaultReplicaSet.topology[].status \
		| grep ONLINE \
		| wc -l)

	if [[ ${online_members} != 3 ]]; then
		echo "expected 3 online members, got ${online_members}"
		exit 1
	fi
}

renew_certificate() {
	certificate="$1"

	local pod_name
	pod_name=$(kubectl get -n "${NAMESPACE}" pods --selector=name=cmctl -o 'jsonpath={.items[].metadata.name}')

	local revision
	revision=$(kubectl get -n "${NAMESPACE}" certificate "$certificate" -o 'jsonpath={.status.revision}')

	kubectl exec -n "${NAMESPACE}" "$pod_name" -- /tmp/cmctl renew "$certificate"

	# wait for new revision
	for i in {1..10}; do
		local new_revision
		new_revision=$(kubectl get -n "${NAMESPACE}" certificate "$certificate" -o 'jsonpath={.status.revision}')
		if [ "$((revision + 1))" == "$new_revision" ]; then
			break
		fi
		sleep 1
	done
}

deploy_cmctl() {
	local service_account="cmctl"

	sed -e "s/percona-server-mysql-operator/$service_account/g" "${DEPLOY_DIR}/rbac.yaml" \
		| yq '(select(.rules).rules[] | select(contains({"apiGroups": ["cert-manager.io"]}))).resources += "certificates/status"' \
		| kubectl apply -n "${NAMESPACE}" -f -
	kubectl apply -n "${NAMESPACE}" -f "${TESTS_CONFIG_DIR}/cmctl.yml"
}

get_user_pass() {
	local user="${1:-root}"
	kubectl -n "${NAMESPACE}" get secret test-secrets -o jsonpath="{.data.${user}}" | base64 --decode
}

get_operator_version() {
	kubectl get crd -n "$NAMESPACE" perconaservermysqls.ps.percona.com -o jsonpath='{.metadata.labels.app\.kubernetes\.io/version}'
}

check_backup_job_labels() {
	local psbackup
	psbackup=$1

	local jobs_count
	jobs_count=$(kubectl get jobs -n "$NAMESPACE" -l "app.kubernetes.io/instance=${psbackup}" -o yaml | yq '.items | length')
	if [ "$jobs_count" -ne 1 ]; then
		echo "There are $jobs_count with app.kubernetes.io/instance=${psbackup} label. We should have only one"
		exit 1
	fi

	local job
	job=$(kubectl get jobs -n "$NAMESPACE" -l "app.kubernetes.io/instance=${psbackup}" -o yaml | yq '.items[0].metadata.name')

	local labels
	labels=$(kubectl get job "$job" -n "$NAMESPACE" -o json | jq -r '.metadata.labels')

	local template_labels
	template_labels=$(kubectl get job "$job" -n "$NAMESPACE" -o json | jq -r '.spec.template.metadata.labels')

	local cluster_name
	cluster_name=$(kubectl get ps-backup -n "$NAMESPACE" "${psbackup}" -o jsonpath='{.spec.clusterName}')

	local expected_labels
	expected_labels=(
		"app.kubernetes.io/component=backup"
		"app.kubernetes.io/instance=$psbackup"
		"app.kubernetes.io/managed-by=percona-server-mysql-operator"
		"app.kubernetes.io/name=xtrabackup"
		"app.kubernetes.io/part-of=percona-server-backup"
	)

	local all_match
	all_match=true

	for entry in "${expected_labels[@]}"; do
		key="${entry%%=*}"
		expected_value="${entry#*=}"
		actual_value=$(echo "$labels" | jq -r --arg key "$key" '.[$key]')

		if [ "$actual_value" != "$expected_value" ]; then
			echo "Label mismatch: $key (expected: $expected_value, found: $actual_value)"
			all_match=false
		fi

		actual_value=$(echo "$template_labels" | jq -r --arg key "$key" '.[$key]')
		if [ "$actual_value" != "$expected_value" ]; then
			echo "Template label mismatch: $key (expected: $expected_value, found: $actual_value)"
			all_match=false
		fi
	done

	if [ "$all_match" != true ]; then
		exit 1
	fi
}

check_scheduled_backup_labels() {
	local psbackup
	psbackup=$1

	local labels
	labels=$(kubectl get ps-backup "$psbackup" -n "$NAMESPACE" -o json | jq -r '.metadata.labels')

	local cluster_name
	cluster_name=$(kubectl get ps-backup -n "$NAMESPACE" "${psbackup}" -o jsonpath='{.spec.clusterName}')

	local expected_labels
	expected_labels=(
		"app.kubernetes.io/managed-by=percona-server-mysql-operator"
		"app.kubernetes.io/name=percona-server-backup"
		"app.kubernetes.io/part-of=percona-server"
		"percona.com/backup-type=cron"
		"percona.com/cluster=${cluster_name}"
	)

	local all_match
	all_match=true

	for entry in "${expected_labels[@]}"; do
		key="${entry%%=*}"
		expected_value="${entry#*=}"
		actual_value=$(echo "$labels" | jq -r --arg key "$key" '.[$key]')

		if [ "$actual_value" != "$expected_value" ]; then
			echo "Label mismatch: $key (expected: $expected_value, found: $actual_value)"
			all_match=false
		fi
	done

	if [ "$all_match" != true ]; then
		exit 1
	fi

	backup_ancestor_label=$(kubectl get ps-backup -n "$NAMESPACE" "${psbackup}" -o jsonpath='{.metadata.labels.percona\.com/backup-ancestor}')
	if [ -z "$backup_ancestor_label" ]; then
		echo "Label percona.com/backup-ancestor is missing"
		exit 1
	fi
}
